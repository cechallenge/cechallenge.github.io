---
title:
feature_text: |
  # Samsung Computer Engineering Challenge 2023
  ## No system, No AI: Let's Play with LLM!
feature_image: "/assets/logos/banner_last.png"
---

Large Language Model(LLM)은 Natural Language Processing(NLP), 번역, 각종 시험(SAT, AP Exams 등), Coding Challenge (LeetCode), 의학 지식 등 다양한 분야에서 높은 성과를 보여주고 있어 수요가 폭발적으로 증가하고 있습니다. LLM을 많은 사람들이 이용하는 서비스로 활성화하기 위해서는 LLM에서 Multiple GPU를 활용하여 Inference의 Latency를 줄이는 것이 매우 중요합니다. 하지만 아쉽게도 Multiple GPU에서 LLM을 효율적으로 Infernece하는 방법이 널리 알려져 있지는 않습니다.

삼성전자 SAIT는 LLM기반 서비스의 확산을 위하여 **Computer Engineering Challenge**를 개최하게 되었습니다. 이번 Challenge의 목표는 높은 정확도를 유지하면서 4개의 GPU를 활용하여 LLM의 Latency를 감소하는 것입니다. 그리고 공정한 평가를 위해 Latency 평가 방식과 데이터셋을 제시하고 각 Submission에 대해 면밀한 분석을 진행 할 예정입니다. Computer Engineering Challenge에 참여한 팀 중에서 선정된 10개 팀은 2차 라운드에서 동일한 Computing Platform을 제공받아 팀에서 제시한 Idea를 구현하고, Latency를 비교하여 평가할 예정입니다.

이번 Computer Engineering Challenge를 통해 더 많은 학생들이 LLM을 가속하는 다양한 Computer Engineering 연구들에 흥미를 갖기를 희망합니다. 저희는 이러한 Computer Engineering 관심 증가가 앞으로 도래할 AI Computing 시대를 앞당기고 더불어 에너지와 비용을 절감하는데 크게 기여할 것으로 기대합니다.
<hr />
The Large-scale Language Models (LLM) can be used for Natural Language Processing(NLP), Translation, Various Tests (SAT, AP Exams, etc.), Coding Challenges (LeetCode), etc. Demand is exploding as it shows many achievements in various fields. For wide use of Large-scale Language Models, It is important to reduce inference time by utilizing a large amount of GPU resources. However, it is not yet widely known how to rapidly infer Large-scale Language Models by efficiently using GPU resources.

SAIT holds the **Computer Engineering Challenge** to spread Large-scale Language Model-based services. The goal of this challenge is to increase inference performance while maintaining high accuracy by utilizing four GPUs for a Large-scale Language Model. The operation of the competition will be conducted in the 1st and 2nd rounds. For a fair evaluation, we will present an inference performance evaluation method and dataset, and conduct qualitative/quantitative evaluation of the submitted results. Among the teams participating in the Computer Engineering Challenge, 10 teams selected through the first round will receive the same computing platform in the second round, implement the ideas suggested by the teams, and award based on the submitted performance evaluation results.

Through this Computer Engineering Challenge, we hope that more students will be interested in various technologies that accelerate Large-scale Language Models. We expect that this increased interest in Computer Engineering will advance the AI Computing era to come in the future and contribute greatly to reducing energy and costs.
